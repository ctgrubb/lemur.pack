---
title: "Extending to Two Dimensions"
output:
  rmarkdown::html_document:
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  eval = TRUE
)
```

```{r packageload, message = FALSE, warning = FALSE}
library(lemur.pack)
library(knitr)
library(kableExtra)
library(proftools)
library(magrittr)
```

This vignette extends \code{vignette("articles/binary-1d-example")} to two dimensions.

# Theory

Recall from the above article:

> For a population $\mathbf{Y}$, sample $\mathbf{X}$, and parameter set $\theta$, we can use Bayes' theorem to get the distribution for $\mathbf{Y}$, conditioned on our observed sample, $\mathbf{x}$.
> 
> \begin{align*}
  f(\theta, \mathbf{Y} = \mathbf{y}| \mathbf{X} = \mathbf{x}) &= \frac{ f(\mathbf{X} = \mathbf{x} | \theta, \mathbf{Y} = \mathbf{y}) f(\theta, \mathbf{Y} = \mathbf{y}) }{ f(\mathbf{X} = \mathbf{x}) } \\
    &\propto f(\mathbf{X} = \mathbf{x} | \theta) f(\mathbf{Y} = \mathbf{y} | \theta) \pi(\theta) \\
    &\propto \pi(\theta | \mathbf{X} = \mathbf{x}) f(\mathbf{Y} = \mathbf{y} | \theta)
\end{align*}

Suppose $X$ and $Y$ are now described by two binary $\{0, 1\}$ variables instead of just one. We have at least two options on how to handle this change.

# Option 1: Direct Extension

One option, which is very simple, is to use the multivariate hypergeometric distribution. Instead of having just two categories like the previous article, we can collapse our two variables into one varaible that would have four categories. Everything from the previous article regarding $K$ space will hold with very little modification. And since the multivariate hypergeometric converges to a multinomial distribution just as the hypergeometric converges to a binomial distribution, the method for working in $p$ space will also work. We simply need to:

 * Use the multivariate hypergeometric distribution for $f(\mathbf{X} = \mathbf{x} | \mathbf{K})$ for $K$ method
 * Use the multinomial distribution for $f(\mathbf{X} = \mathbf{x} | \mathbf{p})$ for $p$ method
 * Change the priors; $p$ will now use a dirichlet prior and we can use a similar marginalized prior for $K$
 * Fix the correction factor
 
## Brief Outline for $K$ Space

Note this will end up working *exactly* the same as if we had one variable with $3$ or more categories. We will definte the multivariate hypergeometric distribution in the same fashion as before, except this time $\mathbf{K}$ and $\mathbf{J}$ are vectors.

First, we need to find a prior $\pi(\mathbf{K})$. Suppose there are $c = 4$ categories formed by crossing our two variables (this could be any number, we just want an index for $\mathbf{K}$). Following the same steps as the simple 1-dimensional example, we have:

\begin{align*}
  \pi(\mathbf{K}) &= \int_{0}^{1} {N \choose {\mathbf{K}_1, ..., \mathbf{K}_c}} \prod_{i = 1}^c \mathbf{p}_i^{\mathbf{K}_i} \frac{1}{\beta(\mathbf{\alpha})} \prod_{i = 1}^c \mathbf{p}_i^{\mathbf{\alpha}_i - 1} d\mathbf{p} \\
    &= {N \choose {\mathbf{K}_1, ..., \mathbf{K}_c}} \frac{\beta(\mathbf{K} + \mathbf{\alpha})}{\beta(\mathbf{\alpha})}

\end{align*}

Now we can use this prior to build a sampler. Lets assume the sample is coming to us in a form like `c(1, 2, 3, 4, ...)`, instead of a matrix. It should be simple to go from `c(0, 0)` to 1, `c(0, 1)` to 2, etc., and vice-versa.


```{r popsim_K}
popsim_K <- function(obs, N, samples = 1000, alpha = 0.5) {
  logcorrection <- function(N, K) {
    -lmnchoose(N, K)
  }

  logprior <- function(K, N, alpha) {
    lmnchoose(N, K) + lmnbeta(K + alpha) - lmnbeta(alpha)
  }

  logpost <- function(K, N, obs, n, alpha) {
    dmvhyper(obs, K, n, log = TRUE) + logprior(K, N, alpha) + logcorrection(N, K)
  }

  n <- length(obs)

  out <- matrix(NA, nrow = samples + 1, ncol = N)
  out[1, ] <- rep(obs, length.out = N)

  current_lp <- logpost(as.numeric(table(out[1, ])), N, J, n, alpha)

  for(i in 2:(samples + 1)) {
    current <- out[i - 1, ]
    for(k in 1:N) {
      proposal <- current
      proposal[k] <- sample(1:max(obs)[-proposal[k]], 1)
      proposal_lp <- logpost(as.numeric(table(out[1, ])), N, J, n, alpha)

      u <- runif(1)
      if(!is.na(proposal_lp) & log(u) <= proposal_lp - current_lp) {
        current <- proposal
        current_lp <- proposal_lp
      }
    }
    out[i, ] <- current
  }
  return(out[-1, ])
}
```
 
# Option 2: Using Conditionals

One alternative is to break $f(\mathbf{X} = \mathbf{x} | \theta)$ into $f(\mathbf{X}_2 = \mathbf{x}_2 | \mathbf{X}_1 = \mathbf{x}_1, \theta) f(\mathbf{X}_1 = \mathbf{x}_1 | \theta)$. This makes it potentially easier to incorporate relationships into the model, if they are known to us. For example, maybe we know $f(X_2 = 0 | X_1 = 0)$ should be $1$; i.e., if $X_1 = 0$, then $X_2 = 0$, always.


